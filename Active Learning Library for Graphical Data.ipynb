{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Library for Graphical Data\n",
    "### Adi Faintuch\n",
    "### University of California, Irvine   -  May 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric import utils\n",
    "import torch_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = Planetoid(root='/tmp/CiteSeer', name='CiteSeer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = Planetoid(root='/tmp/CiteSeer', name='PubMed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "    def forward(self):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    F.nll_loss(model()[data.train_mask], data.y[data.train_mask]).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    logits, accs = model(), []\n",
    "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "    \n",
    "def make_and_update_queries(model, query_size=1, query_type=\"random\"):\n",
    "    if query_type == \"random\":\n",
    "        pool_ind = torch.where(data.pool_mask)[0]\n",
    "        idx = torch.randperm(pool_ind.size(0))[:query_size]\n",
    "        queries = pool_ind[idx]\n",
    "    elif query_type == \"degree\":\n",
    "        degrees = utils.degree(data.edge_index[0,:], num_nodes=data.x.shape[0])\n",
    "        ind = np.argmax((degrees*data.pool_mask).numpy(), axis=0)\n",
    "        queries = torch.tensor([ind])\n",
    "    elif query_type == \"entropy\":\n",
    "        pool_ind = torch.where(data.pool_mask)[0]\n",
    "        probs = model.forward()\n",
    "        probs = probs.detach().numpy()\n",
    "        entropies = entropy(probs, base=2, axis=1)\n",
    "        ind = np.argmax((entropies*data.pool_mask.detach().numpy()), axis=0)\n",
    "        queries = torch.tensor([ind])   \n",
    "        \n",
    "    # All queries are False in the training mask\n",
    "    assert torch.any(data.train_mask[queries]).item() == False\n",
    "    data.train_mask[queries] = True\n",
    "    \n",
    "    # All queries are queryable\n",
    "    assert torch.all(data.pool_mask[queries]).item()\n",
    "    data.pool_mask[queries] = False\n",
    "    \n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "initial_train_size = 10\n",
    "query_size = 1\n",
    "\n",
    "query_methods = [\"random\", \"degree\", \"entropy\"]\n",
    "\n",
    "random_results = []\n",
    "degree_results = []\n",
    "entropy_results = []\n",
    "\n",
    "for query in query_methods:\n",
    "    for i in range(3):\n",
    "        data = dataset[0]\n",
    "        original_train_size = data.train_mask.sum().item()\n",
    "        print(\"original train size: \", original_train_size)\n",
    "        data = data.to(device)\n",
    "        data.pool_mask = data.train_mask.clone()\n",
    "        data.pool_mask[:initial_train_size] = False\n",
    "        data.train_mask[initial_train_size:] = False\n",
    "        all_queries = []\n",
    "        active_accuracies = []\n",
    "        for active_q in range((original_train_size - initial_train_size) // query_size):\n",
    "            model, data = Net().to(device), data.to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "            best_val = -1.\n",
    "            best_model = None\n",
    "            acc_list = [-1., -1., -1.]\n",
    "\n",
    "            print(f\"Train Size {data.train_mask.sum().item()} Pool Size {data.pool_mask.sum().item()}\")\n",
    "            for epoch in range(1, 201):\n",
    "                train()\n",
    "                train_acc, val_acc, test_acc = test()\n",
    "                if val_acc > best_val:\n",
    "                    acc_list[0] = train_acc\n",
    "                    acc_list[1] = val_acc\n",
    "                    acc_list[2] = test_acc\n",
    "                    best_val = val_acc \n",
    "                    best_model = copy.deepcopy(model)\n",
    "\n",
    "            log = 'Active Run: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "            print(log.format(active_q, acc_list[0], acc_list[1], acc_list[2]))\n",
    "            active_accuracies.append(acc_list)\n",
    "\n",
    "            queries = make_and_update_queries(best_model, query_size=query_size, query_type=query)\n",
    "            queries_tolist = queries.tolist()\n",
    "            all_queries += queries_tolist\n",
    "            all_queries += queries.tolist()\n",
    "\n",
    "        if query == \"random\":\n",
    "            print(\"Random\")\n",
    "            random_results.append(np.array(active_accuracies))\n",
    "        elif query == \"degree\":\n",
    "            print(\"Degree\")\n",
    "            degree_results.append(np.array(active_accuracies))\n",
    "        else:\n",
    "            print(\"Entropy\")\n",
    "            entropy_results.append(np.array(active_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(3):\n",
    "    plt.title(\"Cora Random Results\")\n",
    "    plt.xlabel(\"Train Size (# Nodes)\")\n",
    "    plt.ylabel(\"Accuracy %\")\n",
    "    l = \"random, \" + str(b)\n",
    "    plt.plot(random_results[b][:, 2], label=l)\n",
    "\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(3):\n",
    "    plt.title(\"Cora Degree Results\")\n",
    "    plt.xlabel(\"Train Size (# Nodes)\")\n",
    "    plt.ylabel(\"Accuracy %\")\n",
    "    l = \"degree, \" + str(b)\n",
    "    plt.plot(degree_results[b][:, 2], label=l)\n",
    "\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(3):\n",
    "    plt.title(\"Cora Entropy Results\")\n",
    "    plt.xlabel(\"Train Size (# Nodes)\")\n",
    "    plt.ylabel(\"Accuracy %\")\n",
    "    l = \"entropy, \" + str(b)\n",
    "    plt.plot(entropy_results[b][:, 2], label=l)\n",
    "\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Cora Combined Results\")\n",
    "plt.xlabel(\"Train Size (# Nodes)\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "\n",
    "l = \"random\"\n",
    "plt.plot(np.mean(random_results, axis=0)[:, 2], label=l)\n",
    "plt.legend();\n",
    "\n",
    "l = \"degree\"\n",
    "plt.plot(np.mean(degree_results, axis=0)[:, 2], label=l)\n",
    "plt.legend();\n",
    "\n",
    "l = \"entropy\"\n",
    "plt.plot(np.mean(entropy_results, axis=0)[:, 2], label=l)\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
